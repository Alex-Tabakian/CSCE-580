1. What do the accuracy and loss curves tell you about the fine-tuning process?

Accuracy and loss curves show how well a model learns. A rise in validation accuracy with a decrease in validation loss indicates correct learning. If validation loss rises while training loss drops, it suggests overfitting.

2. How does the fine-tuned DistilBERT model compare to the classical ML model? What advantages or limitations do transformers present over classical algorithms?

The DistilBERT model achieves better accuracy than the classical ML model. Transformers can capture word context while classical models only rely on word frequency.

3. What insights can you draw from the confusion matrix? Are there any patterns in the
misclassifications?


4. Why might the fine-tuned model outperform the base model?


5. Which model would you recommend for deployment in a real-world scenario, and why?
Consider both performance and efficiency in your answer.
